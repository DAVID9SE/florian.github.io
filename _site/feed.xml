<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Florian Hartmann</title>
    <description></description>
    <link>https://florian.github.io//</link>
    <atom:link href="https://florian.github.io//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 18 Jul 2018 07:43:03 -0700</pubDate>
    <lastBuildDate>Wed, 18 Jul 2018 07:43:03 -0700</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      <item>
        <title>Estimation Theory and Machine Learning</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;Often it is not possible or simply impractical to compute certain values exactly.
This might be because it is too expensive computationally or because not enough information is available.
Instead, these values can be estimated.
The quality of estimates varies.
In statistics, this concept is formalized in estimation theory [1, 2].&lt;/p&gt;

&lt;p&gt;The first part of this blog post introduces the fundamentals behind estimators.
In the second part, it is shown how they can be applied to machine learning in two different ways.
One of these applications is quantifying the quality of models.
Since models can generally not be perfect for complex problems, it is useful to try to describe how well they work.&lt;/p&gt;

&lt;p&gt;Additionally, estimation theory is useful to understand different versions of gradient descent.
Typically, the gradient is only estimated using methods like mini-batch or stochastic gradient descent.
Here, estimation theory can be used to explain the ideas behind these techniques.&lt;/p&gt;

&lt;h3 id=&quot;estimators-and-their-properties&quot;&gt;Estimators and their properties&lt;/h3&gt;

&lt;p&gt;An &lt;em&gt;estimator&lt;/em&gt; is a function that estimates a value based on other observations.
This process can involve randomness.
For example because the function itself is random or because there is random noise in the observations it uses.&lt;/p&gt;

&lt;h4 id=&quot;bias&quot;&gt;Bias&lt;/h4&gt;

&lt;p&gt;One measure for the quality of an estimator \(\theta\) is its &lt;em&gt;bias&lt;/em&gt; or how far off its estimate \(\tilde{X}\) is on average from the true value \(X\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\operatorname{bias}({\theta}) = \mathbb{E}[\tilde{X}] - X&lt;/script&gt;

&lt;p&gt;where the expected value is over the randomness involved in \(\theta\).&lt;/p&gt;

&lt;p&gt;If the bias of an estimator is \(0\), it is called an &lt;em&gt;unbiased estimator&lt;/em&gt;.
This is generally a desirable property to have [3] because it means that the estimator is correct on average.
If one samples for long enough from the estimator, the average converges to the true value \(X\).
This is due to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_large_numbers&quot;&gt;law of large numbers&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: If \(k\) estimators all produce unbiased estimates \(\tilde{X}_1, \dots, \tilde{X}_k\) of \(X\), then any weighted average of them is also an unbiased estimator.
The full estimate is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{X} = w_1 * \tilde{X}_1 + \ldots + w_k * \tilde{X}_k&lt;/script&gt;

&lt;p&gt;where the sum of weights \(\sum_{i = 1}^k w_i = 1\) needs to be normalized.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: The unbiasedness is due to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Expected_value#Linearity&quot;&gt;linearity of expectation&lt;/a&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
	\mathbb{E}[\tilde{X}] &amp; = \mathbb{E}[w_1 * \tilde{X}_1 + \ldots + w_k * \tilde{X}_k] \\
	              &amp; = w_1 * \mathbb{E}[\tilde{X}_1] + \ldots + w_k * \mathbb{E}[\tilde{X}_k] \\
	              &amp; = w_1 * X + \ldots + w_k * X \\
	              &amp; = X
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;This theorem about unbiased estimators is going to prove to be useful later on.&lt;/p&gt;

&lt;h4 id=&quot;variance&quot;&gt;Variance&lt;/h4&gt;

&lt;p&gt;However, even if we have an unbiased estimator, its individual estimates can still be far off from the true value.
To quantify how consistently an estimator is close to the true value, another statistic is required.
Commonly, the &lt;em&gt;variance&lt;/em&gt; of the estimator is considered here:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\operatorname{Var}[\theta] = \mathbb{E}[(\tilde{X} - X)^2]&lt;/script&gt;

&lt;p&gt;It is defined as the mean squared distance between the estimate and the value to be estimated.&lt;/p&gt;

&lt;h3 id=&quot;bias-variance-tradeoff&quot;&gt;Bias-variance tradeoff&lt;/h3&gt;

&lt;p&gt;Many different things can be analyzed using estimators.
For example, statistical models can be seen as estimators.
They use observations, or data, to make predictions.
These predictions are generally not perfect because randomness is involved and only a limited amount of information is available.
Thus, it makes sense to analyze statistical models in terms of bias and variance.&lt;/p&gt;

&lt;p&gt;A central problem when building models is balancing underfitting and overfitting.
If the training data is just memorized, the model does not generalize well to new data.
This is a case of overfitting.
The opposite issue, only barely matching the pattern in the training data, is called underfitting.&lt;/p&gt;

&lt;p&gt;This problem is also known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias–variance_tradeoff&quot;&gt;&lt;em&gt;bias-variance tradeoff&lt;/em&gt;&lt;/a&gt; [4, 5].
If the model has a high bias, its predictions are off, which corresponds to underfitting.
If overfitting occurred, i.e. the data is matched too well, the estimates have a high variance.
By resampling the data that the model was built on, totally different estimates are generated.
This is because the model is now based on different random noise.&lt;/p&gt;

&lt;p&gt;Generally, it is not possible to perfectly optimize both, bias and variance, so they need to be balanced here.
In other words, we accept a certain bias of the model to keep its variance low.
A good tradeoff between the two needs to be achieved.&lt;/p&gt;

&lt;h3 id=&quot;gradient-descent&quot;&gt;Gradient descent&lt;/h3&gt;

&lt;p&gt;In supervised machine learning, we compare our model’s predictions to the true labels.
This is done using a loss function.
If a set of data points \(x_1, \dots, x_n\) and labels \(y_1, \dots\, y_n\) is given, then the full loss is defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \frac{1}{n} \sum\limits_{i = 1}^n \operatorname{loss}(f(x_i), y_i)&lt;/script&gt;

&lt;p&gt;where \(\operatorname{loss}\) is a function that compares a prediction \(p\) to the correct answer \(y\).
One choice for the loss function might be the quadratic error:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\operatorname{loss}(p, y) = (p - y)^2&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;Gradient descent&lt;/a&gt; optimizes the parameters used in \(f\) by computing the gradient of the loss with respect to these parameters.
This gradient is then used to continually improve the parameters step by step.&lt;/p&gt;

&lt;h4 id=&quot;full-batch-gradient-descent&quot;&gt;Full-batch gradient descent&lt;/h4&gt;

&lt;p&gt;To compute the gradient \(\nabla L\) of the loss, we can make use of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient#Linearity&quot;&gt;linearity of the gradient operator&lt;/a&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
	\nabla L &amp; = \nabla \frac1n \sum\limits_{i = 1}^n \operatorname{loss}(f(x_i), y_i) \\
	         &amp; = \frac1n \sum\limits_{i = 1}^n \nabla \operatorname{loss}(f(x_i), y_i)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The method that uses the gradient given above is sometimes referred to as &lt;em&gt;full-batch gradient descent&lt;/em&gt; because it fully uses the available training data in each iteration.
In many cases, \(n\) is a very large value and computing the full update \(\nabla L\) is expensive.
Since computing the gradient is by far the most expensive part of gradient descent, it makes sense to try to make this more efficient.&lt;/p&gt;

&lt;p&gt;Computing the gradient as shown above is especially inefficient if there is duplicated training data.
If the training set consists of 10 copies of a different dataset, then the evaluation of the formula above is unnecessarily expensive.
Every required calculation is repeated 10 times.
While this is an extreme example, it does happen in practice that much of the training data is similar.
To save time, it often makes sense to only use a part of the data to estimate the gradient.&lt;/p&gt;

&lt;h4 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic gradient descent&lt;/h4&gt;

&lt;p&gt;In &lt;em&gt;stochastic gradient descent&lt;/em&gt; (&lt;em&gt;SGD&lt;/em&gt;), a single data point \(x\) and label \(y\) are sampled uniformly from the training set.
The true gradient \(\nabla L\) is then estimated using only this data point and label:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla \tilde{L} = \nabla \operatorname{loss}(f(x), y)&lt;/script&gt;

&lt;p&gt;It is easy to see that \(\nabla \tilde{L}\) is an unbiased estimator of \(\nabla L\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
	\mathbb{E}[\nabla \tilde{L}] &amp; = \sum\limits_{i = 1}^n \frac{1}{n} \nabla \operatorname{loss}(f(x_i), y_i)  \\
	                     &amp; = \frac1n \nabla \sum\limits_{i = 1}^n \operatorname{loss}(f(x_i), y_i) \\
	                     &amp; = \nabla L
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The computations for SGD can be performed very quickly but still give us an unbiased estimate of the true gradient.
This property is the reason why optima can be found using this algorithm.
While individual estimates are off, the randomness averages out over iterations and the parameters still move into a sensible direction overall.
Since iterations are much cheaper, many more of them can be performed and this is a major improvement to computing the full gradient.&lt;/p&gt;

&lt;h4 id=&quot;mini-batch-gradient-descent&quot;&gt;Mini-batch gradient descent&lt;/h4&gt;

&lt;p&gt;These individual SGD estimates can have a large variance however, leading to noisy and jumpy updates.
A further improvement over this method is &lt;em&gt;mini-batch gradient descent&lt;/em&gt;.
Instead of just sampling one data point, we sample a small batch of \(k\) examples.
The estimated gradient is an average of all \(k\) single estimates.&lt;/p&gt;

&lt;p&gt;Each of these individual estimators is unbiased since SGD itself is unbiased.
As shown in the theorem earlier, a weighted combination of them still remains an unbiased estimator.
Thus, mini-batch gradient descent is also an unbiased way of computing gradient estimates.&lt;/p&gt;

&lt;p&gt;Mini-batch gradient descent does have much less variance, however, because more data is used to compute the estimate.
This makes the optimization process more stable compared to using SGD.&lt;/p&gt;

&lt;p&gt;Most gradient computations can be formulated using linear algebra operations.
These calculations can be parallelized very well on GPUs [6].
So with appropriate hardware there is no significant performance penalty for using \(1 &amp;lt; k \ll n\) data points to compute the estimate.
Thus mini-batch gradient descent is typically not much slower than SGD but leads to a more stable optimization process.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Estimators provide an elegant way of analyzing the quality of estimates.
In machine learning, estimates play an important role because data contains a lot of random noise and because it is often more practical to only estimate values.
The quality of statistical models can be described in terms of bias and variance.
Too much bias corresponds to underfitting, while too much variance is equivalent to overfitting.
The training process needs to find a tradeoff between these two.&lt;/p&gt;

&lt;p&gt;To compute the gradient for the optimization process, it is expensive to use all data points.
By randomly sampling them, we can compute unbiased estimates in a much faster way.
If this is done using a large enough sample, the variance of these estimates does not have to be large.
By properly choosing the sample size, the optimization process can thus be speeded up significantly.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] Diez, D.M., Barr, C.D. and Cetinkaya-Rundel, M., 2012. OpenIntro statistics (Vol. 12). CreateSpace.&lt;/p&gt;

&lt;p&gt;[2] Härdle, W. and Simar, L., 2007. Applied multivariate statistical analysis (Vol. 22007, pp. 1051-8215). Berlin: Springer. Vancouver&lt;/p&gt;

&lt;p&gt;[3] Voinov, V.G. and Nikulin, M.S., 2012. Unbiased Estimators and Their Applications: Volume 1: Univariate Case (Vol. 263). Springer Science &amp;amp; Business Media.&lt;/p&gt;

&lt;p&gt;[4] Raul Rojas. The bias-variance dilemma. Freie University, Berlin, Tech. Rep, 2015.&lt;/p&gt;

&lt;p&gt;[5] Friedman, J., Hastie, T. and Tibshirani, R., 2001. The elements of statistical learning (Vol. 1, No. 10). New York, NY, USA:: Springer series in statistics.&lt;/p&gt;

&lt;p&gt;[6] Navarro, C.A., Hitschfeld-Kahler, N. and Mateu, L., 2014. A survey on parallel computing and its applications in data-parallel problems using GPU architectures. Communications in Computational Physics, 15(2), pp.285-329.&lt;/p&gt;
</description>
        <pubDate>Tue, 17 Jul 2018 00:00:00 -0700</pubDate>
        <link>https://florian.github.io//estimators/</link>
        <guid isPermaLink="true">https://florian.github.io//estimators/</guid>
        
        
        <category>machine-learning,</category>
        
        <category>optimization</category>
        
      </item>
    
      <item>
        <title>Federated Learning</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;In the past few years, machine learning has led to major breakthroughs in various areas, such as natural language processing, computer vision and speech recognition [1].
Much of this success has been based on collecting huge amounts of data. For example, one of Facebook’s latest &lt;a href=&quot;https://github.com/facebookresearch/Detectron&quot;&gt;Detectron&lt;/a&gt; models for object detection used &lt;a href=&quot;https://code.facebook.com/posts/1700437286678763/advancing-state-of-the-art-image-recognition-with-deep-learning-on-hashtags/&quot;&gt;3.5 billion images&lt;/a&gt; from Instagram for training.&lt;/p&gt;

&lt;p&gt;For some applications of machine learning this need of collecting data can be incredibly privacy-invasive.
One such example application is predicting the next word that a person is going to use by considering the previous words.
This is typically done using machine learning nowadays, e.g. with recurrent neural networks and LSTMs [2].
Although it is possible to train such a model using a text corpus from Wikipedia, the language found there differs from the one typically used by people in daily life.&lt;/p&gt;

&lt;p&gt;One potential use case for such a model is to improve the results of speech recognition, another one to predict the next word that is typed on a mobile phone to help people type more quickly.
In both cases, it would be beneficial to directly train on that data instead of using text from Wikipedia.
This would allow training a model based on the same data distribution that is also used for making predictions.
However, directly collecting this data is a terrible idea because it is extremely privacy-sensitive.
Users do not want that everything they type is sent to a server.&lt;/p&gt;

&lt;p&gt;Sending only randomized versions of the original data to the server, based on the ideas of &lt;a href=&quot;/differential-privacy/&quot;&gt;Differential Privacy&lt;/a&gt;, is one potential solution to this problem.
The second solution is &lt;a href=&quot;https://research.googleblog.com/2017/04/federated-learning-collaborative.html&quot;&gt;&lt;em&gt;Federated Learning&lt;/em&gt;&lt;/a&gt;, a new approach to machine learning where the training data does not leave the users’ computer at all.
Instead of sharing their data, users compute weight updates themselves using their locally available data.
It is a way of training a model without directly inspecting users’ data on a server.
This blog posts gives a high-level introduction to Federated Learning and the challenges that arise in this problem setting.&lt;/p&gt;

&lt;h3 id=&quot;federated-optimization&quot;&gt;Federated Optimization&lt;/h3&gt;

&lt;p&gt;Federated Learning is a collaborative form of machine learning where the training process is distributed among many users.
A server has the role of coordinating everything but most of the work is not performed by a central entity anymore but by a &lt;em&gt;federation&lt;/em&gt; of users.&lt;/p&gt;

&lt;p&gt;Before the start of the actual training process, the server initializes the model.
Theoretically, this can be done arbitrarily, by using any of the common neural network initialization strategies or the equivalent for other model types.
In practice, it is a good idea to use publicly available data to pretrain the model.
For the example given above, this could be done by using text from Wikipedia.
Although this does not produce the best possible model, it is a good starting point and can reduce the time until the Federated Learning process converges.&lt;/p&gt;

&lt;p&gt;After the model is initialized, a certain number of users are randomly selected to improve the model.
Each user receives the current model from the server and uses their locally
available data to compute a model update \(H_i\).
All these updates are sent back to the server where they are averaged, weighted by the number of training examples that the respective clients used.
The server then applies this update to the model, typically by using some form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;gradient descent&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/posts/federated-learning/iteration.png&quot; width=&quot;600&quot; style=&quot;margin: 25px auto; display: block&quot; alt=&quot;One iteration of a federated learning system&quot; /&gt;&lt;/p&gt;

&lt;p&gt;All of this is called a communication round.
This process is then performed many times until the parameters of the model stabilize.
Ideally, this happens after as few communication rounds as possible.
To this end, it helps if the updates given by the users have a high quality.
For models that we train based on gradient descent, one useful approach is to take several steps of stochastic gradient descent locally on the user’s computer before sending the weight update back to the server [3].&lt;/p&gt;

&lt;p&gt;The hyperparameter that determines how many users are sampled in each communication round also influences how many rounds are required until convergence is reached.
However, at some point the average that is computed stabilizes and utilizing more users per round does not help to significantly reduce the number of communication rounds further.
Thus, it makes sense to only query a smaller number of users in each each iteration.&lt;/p&gt;

&lt;h3 id=&quot;applications&quot;&gt;Applications&lt;/h3&gt;

&lt;p&gt;In principle, this scheme can be applied to any model for which some notion of updates can be defined.
This naturally includes everything based on gradient descent, which most of the popular models nowadays are.
Linear regression, logistic regression, neural networks and support vector machines can all be used for Federated Learning by letting users compute gradients.&lt;/p&gt;

&lt;p&gt;There are other models that are not based on gradients but where it is possible to define updates.
For k-means clustering, updates could correspond to moving the cluster centers.
If users compute the position of the new centers based on their local data, the weighted average across all these results gives us the true new position.
Similar averages can be used with the &lt;a href=&quot;http://theory.stanford.edu/~tim/s15/l/l8.pdf&quot;&gt;power iteration method&lt;/a&gt; to implement a distributed version of PCA.
For some other models like decision trees, it can be much harder to think of a federated version that allows for continuous updates.&lt;/p&gt;

&lt;p&gt;In terms of data, Federated Learning is especially useful in situations where users generate and label data themselves implicitly.
This is the case for the application of trying to predict the next word.
While users type on their keyboards, the model tries to predict the next word.
As soon as the user typed the next word, a new data point is created and the true label (the last word) is determined.
The model can then automatically update itself without having to store the data permanently.
In such a situation, Federated Learning is extremely powerful because models can be trained with a huge amount of data that is not stored and not directly shared at all.&lt;/p&gt;

&lt;h3 id=&quot;unique-characteristics&quot;&gt;Unique Characteristics&lt;/h3&gt;

&lt;p&gt;While Federated Learning might sound similar to distributed machine learning on a technical level, there are some major differences to applications in data centers where the training data is distributed among many machines [4].&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Huge number of clients&lt;/strong&gt;: Since machine learning generally requires a lot of data, the applications that use it have to have many users. Every one of these users could theoretically participate in Federated Learning, making it far more distributed than anything in a data center&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Non-identical distributions&lt;/strong&gt;: In a data center setting, it is possible to make sure that every machine has a representative set of data so that all updates look very similar. In Federated Learning, this can not be guaranteed. We have to expect that users generate data from completely different distributions, i.e. we cannot make &lt;a href=&quot;https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables&quot;&gt;iid&lt;/a&gt; assumptions. While similar users might have similar local training data, two randomly picked users could produce very different weight updates&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unbalanced number of samples&lt;/strong&gt;: Along the same lines, we cannot expect most users to have the same number of local training examples. There could be users with only a handful of data points, while others might have thousands&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Slow and instable communication&lt;/strong&gt;: In a data center, it is expected that nodes can communicate comparatively quickly with each other and that it is ensured that messages do not get lost. In Federated Learning, these assumptions can not be made. Uploads are typically going to be much &lt;a href=&quot;http://www.speedtest.net/reports/united-states/&quot;&gt;slower&lt;/a&gt; than downloads and, especially if the connection is from a cell phone, it might be extremely slow. Some clients might also currently not be connected to the internet and will not respond at all&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These properties motivate why Federated Learning requires its own specialized algorithms.&lt;/p&gt;

&lt;h3 id=&quot;compression&quot;&gt;Compression&lt;/h3&gt;

&lt;p&gt;Neural networks commonly have millions of parameters nowadays.
Sending updates for so many values to a server leads to huge communication costs with a growing number of users and iterations.
Thus, a naive approach to sharing weight updates is not feasible for larger models.
Since uploads are typically much slower than downloads, it is acceptable that users have to download the current model, while compression methods should be applied to the uploaded data.&lt;/p&gt;

&lt;p&gt;Of course, lossless compression techniques can be used and it might make sense to only send updates once a good network connection is possible.
Additionally, specialized compression techniques for Federated Learning can be applied [4].
These are lossy compression algorithms, meaning that some information is lost.
Still, good models can be learned since these methods were developed (or later analyzed) with Federated Learning in mind.&lt;/p&gt;

&lt;p&gt;On a high level, compression algorithms for Federated Learning can be put into two classes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Sketched updates&lt;/em&gt;: Clients compute a normal weight update and perform a compression afterwards. One of the more sophisticated such techniques is &lt;a href=&quot;/probabilistic-quantization/&quot;&gt;Probabilistic Quantization&lt;/a&gt;, which I described in more detail in another blog post&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Structured updates&lt;/em&gt;: During the optimization process, the update is restricted to be of a form that allows for an efficient compression. For example, the updates might be forced to be sparse or low-rank. The optimization then finds the best possible update of this form&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are no strong guarantees regarding which method works the best.
It heavily depends on the problem and the distributions of the updates.
Like in many parts of machine learning, different methods just have to be tested and compared empirically.&lt;/p&gt;

&lt;h3 id=&quot;privacy&quot;&gt;Privacy&lt;/h3&gt;

&lt;p&gt;On a first look, Federated Learning seems like a method that it is very privacy-friendly.
However, one could think about an attacker that analyzes the weight updates sent by users to make conclusions about their data [5].
If the behavior of the coordinating server is also adversarial, the model could be a neural network with so much capacity that it overfits badly.
Since neural networks are &lt;a href=&quot;https://en.wikipedia.org/wiki/Universal_approximation_theorem&quot;&gt;universal function approximators&lt;/a&gt;, this model might just learn to approximate the function that directly acts as a look-up table to the data used for training.
In this case, the user’s data would not be private because it is still represented more or less clearly in the model.&lt;/p&gt;

&lt;p&gt;While this might sound unlikely if not done on purpose, there have been experiments that show it is possible to reconstruct some data points.
In one case, researchers were able to reconstruct images of faces that were used to train a face recognition model [6].&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/differential-privacy/&quot;&gt;Differential Privacy&lt;/a&gt;, which I wrote about in another post, is one solution to this problem.
By formalizing what privacy means, we can analyze how well the learning algorithm respects privacy.
To employ this technique to Federated Learning, the notion of privacy is adapted to a user level: It should be very hard to tell whether a user contributed to the training of the model.
This is done using a stochastic framework.
By adding noise to update data shared by the user, the reports of individuals become much harder to analyze, while the noise can be estimated well for the aggregated data.&lt;/p&gt;

&lt;p&gt;Concretely, this involves several changes to the previous Federated Learning algorithm [6]:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Users are randomly sampled with some probability instead of always sampling a fixed number of users. This is to make sure that users can still be sampled independently of each other&lt;/li&gt;
  &lt;li&gt;The updates that users send to the server need to have a limited L2 norm. The motivation for this is that it should prevented that individuals can be identified because they are the only ones that would propose large updates. In the case of neural networks this corresponds to &lt;a href=&quot;https://hackernoon.com/gradient-clipping-57f04f0adae&quot;&gt;gradient clipping&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Noise is added to the final update for the model, similar to most Differential Privacy algorithms&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In experiments, it has been shown that the same accuracy as before can be achieved with these changes.
However, the computational cost to get there is much higher.
In a real implementation, this could correspond to a slower convergence rate.&lt;/p&gt;

&lt;h3 id=&quot;encryption&quot;&gt;Encryption&lt;/h3&gt;

&lt;p&gt;Encryption for Federated Learning is a topic that is close to the privacy aspect previously discussed.
By using cryptography techniques, it is possible to make sure that the updates of individuals can only be read when enough users submitted updates [7].
This makes it much harder for an attacker to make conclusions about the training data based on intercepted network activity.
To be able to try that, they would need to intercept the messages of many users.&lt;/p&gt;

&lt;h3 id=&quot;personalization&quot;&gt;Personalization&lt;/h3&gt;

&lt;p&gt;A potential extension of Federated Learning could be customization.
While users help to train a central model, they also locally personalize it using their own data.
A simple implementation of this is a two-phase training process.
In the first step, a central model is collaboratively trained by all users.
After that, users locally adapt the model to their own preferences.&lt;/p&gt;

&lt;p&gt;This approach has an obvious drawback: Once users start personalizing the model, they cannot help to train the central one anymore.
That might be bad because there could be situations where the model becomes outdated.
A second approach is to personalize the input that the model receives.
Additionally to the actual input, the model also receives a personalized vector which encodes the preferences of the respective user.&lt;/p&gt;

&lt;p&gt;Once the model itself was trained to a sufficient quality, users start optimizing the personalized vector as well.
The centralized model is still improved periodically.
Over time, the centralized model keeps improving and adapting to changes, while users can also keep improving their personalization settings.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Current machine learning approaches require the availability of large datasets.
These are usually created by collecting huge amounts of data from users.
Federated Learning is a more flexible technique that allows training a model without directly seeing the data.
Although it is a distributed algorithm, it is very different from the data center use of machine learning.
Many guarantees about distributions can not be made and communication is often slow and instable.&lt;/p&gt;

&lt;p&gt;To be able to perform Federated Learning efficiently, optimization algorithms can be adapted and various compression schemes can be used.
The privacy aspect can be tackled using differential privacy and encryption.
Since the system in general is quite flexible, it can be adapted to allow for locally personalized models.
Although there have been several papers about Federated Learning, it is still quite new and not many uses of it were reported by the industry yet.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] LeCun, Y., Bengio, Y. and Hinton, G., 2015. Deep learning. nature,
521(7553), p.436.&lt;/p&gt;

&lt;p&gt;[2] Sundermeyer, M., Schlüter, R. and Ney, H., 2012. LSTM neural networks for
language modeling. In Thirteenth Annual Conference of the International Speech
Communication Association.&lt;/p&gt;

&lt;p&gt;[3] McMahan, H.B., Moore, E., Ramage, D. and Hampson, S., 2016. Communication-efficient learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629.&lt;/p&gt;

&lt;p&gt;[4] Konečný, J., McMahan, H.B., Yu, F.X., Richtárik, P., Suresh, A.T. and Bacon, D., 2016. Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492.&lt;/p&gt;

&lt;p&gt;[5] McMahan, H.B., Ramage, D., Talwar, K. and Zhang, L., 2017. Learning differentially private language models without losing accuracy. arXiv preprint arXiv:1710.06963.&lt;/p&gt;

&lt;p&gt;[6] Fredrikson, M., Jha, S. and Ristenpart, T., 2015, October. Model inversion attacks that exploit confidence information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (pp. 1322-1333). ACM.&lt;/p&gt;

&lt;p&gt;[7] Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.B., Patel, S., Ramage, D., Segal, A. and Seth, K., 2017, October. Practical Secure Aggregation for Privacy-Preserving Machine Learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (pp. 1175-1191). ACM.&lt;/p&gt;
</description>
        <pubDate>Wed, 09 May 2018 00:54:00 -0700</pubDate>
        <link>https://florian.github.io//federated-learning/</link>
        <guid isPermaLink="true">https://florian.github.io//federated-learning/</guid>
        
        
        <category>machine-learning,</category>
        
        <category>federated-learning</category>
        
      </item>
    
      <item>
        <title>RProp</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;em&gt;RProp&lt;/em&gt; is a popular gradient descent algorithm that only uses the signs of
gradients to compute updates. It stands for &lt;em&gt;Resilient Propagation&lt;/em&gt; and works
well in many situations because it adapts the step size dynamically for each
weight independently. This blog posts gives an introduction to RProp
and motivates its design choice of ignoring gradient magnitudes.&lt;/p&gt;

&lt;p&gt;Most gradient descent variants use the sign and the magnitude of the gradient.
The gradient points in the direction of steepest ascent.
Because we typically want to find a minimum, we follow the gradient in the
opposite direction.
This direction is completely determined by the sign of the gradient.&lt;/p&gt;

&lt;h3 id=&quot;gradient-magnitudes&quot;&gt;Gradient magnitudes&lt;/h3&gt;

&lt;p&gt;To decide on the step size, a scaled version of the gradient’s magnitude is
generally used by most gradient descent algorithms.
This heuristic often works well but there is no guarantee that it is
always a good choice.
To see that it can work extremely badly, and does not have
to contain valuable information, we consider a function \(f\).
The plots below show \(f\) as well as two scaled versions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/rprop/scales.png&quot; alt=&quot;Three functions with the same optima but vastly different gradients&quot; /&gt;&lt;/p&gt;

&lt;p&gt;All three of these functions have the exact same optima, so the step updates
using gradient descent should all be similar.
However, if we determine the step size using the gradient’s
magnitude, then the step sizes for the three functions are going to differ by
orders of magnitude.
Even worse, the gradient virtually vanishes for the second function and explodes
for the third.&lt;/p&gt;

&lt;p&gt;This shows that the gradient’s magnitude does not have to contain useful
information for determining the step size.
Even though optima can still be found by choosing appropriate learning rates,
this should make it clear that using the gradient’s magnitude at all is sometimes questionable.
Using a fixed learning rate will also fail if only some parts of the function
are scaled.&lt;/p&gt;

&lt;h3 id=&quot;updating-weights&quot;&gt;Updating weights&lt;/h3&gt;

&lt;p&gt;Modern gradient descent variants try to circumvent this problem by dynamically
adapting the step size.
RProp does this in a way that only requires the sign of the gradient.
By ignoring the gradient’s magnitude, RProp has no problems if a function has a few very
steep areas.&lt;/p&gt;

&lt;p&gt;Concretely, RProp uses a different step size for each dimension.
Let \(\eta_i^{(t)}\) be the step size for the \(i\)-th weight in the \(t\)-th
iteration of gradient descent.
The value for the first and second iteration, \(\eta_i^{(0)}\) and
\(\eta_i^{(1)}\), is a hyperparameter that needs to be chosen up front.
This step size is then dynamically adapted for each weight, depending on the gradient.&lt;/p&gt;

&lt;p&gt;The weights themselves are updated using&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_i^{(t)} = w_i^{(t - 1)} - \eta_i^{(t - 1)} * \operatorname{sgn}\left(\frac{\partial E^{(t -
	1)}}{\partial w_i^{(t - 1)}}\right)&lt;/script&gt;

&lt;p&gt;where the sign of the partial derivative of the error in the last step
with respect to the respective weight is computed.
We go into the direction of descent using the determined step size.&lt;/p&gt;

&lt;h3 id=&quot;adapting-the-step-size&quot;&gt;Adapting the step size&lt;/h3&gt;

&lt;p&gt;In each iteration of RProp, the gradients are computed and the step sizes are
updated for each dimension individually.
This is done by comparing the gradient’s sign of the current and previous
iteration.
The idea here is the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When the signs are the same, we go into the same direction as in the
  previous iteration. Since this seems to be a good direction, the step size
  should be increased to go to the optimum more quickly&lt;/li&gt;
  &lt;li&gt;If the sign changed, the new update is going into a different direction.
  This means that we just jumped over an optimum.
  The step size should be decreased to avoid jumping over the optimum again&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A visualization of this idea is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/rprop/jumps.png&quot; alt=&quot;The gradient direction changes when jumping over optima&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To implement this update scheme, the following formula is used:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\eta_i^{(t)} = \begin{cases}
	\min(\eta_i^{(t - 1)} * \alpha, \eta_{\max}) &amp; \text{if } \frac{\partial E^{(t)}}{\partial w_i^{(t)}} * \frac{\partial E^{(t - 1)}}{\partial w_i^{(t - 1)}} &gt; 0 \\
	\max(\eta_i^{(t - 1)} * \beta, \eta_{\min}) &amp; \text{if } \frac{\partial E^{(t)}}{\partial w_i^{(t)}} * \frac{\partial E^{(t - 1)}}{\partial w_i^{(t - 1)}} &lt; 0 \\
	\eta_i^{(t - 1)} &amp; \text{otherwise}
	\end{cases}
\label{eq:rprop} %]]&gt;&lt;/script&gt;

&lt;p&gt;where \(\alpha &amp;gt; 1 &amp;gt; \beta\) scale the step size, depending on whether
the speed should be increased or decreased. The step size is then clipped using
\(\eta_{\min}\) and \(\eta_{\max}\) to avoid that it becomes too large or small.
If a gradient was zero, a local optimum for this weight was found and the step
size is not changed.&lt;/p&gt;

&lt;h3 id=&quot;hyperparameters&quot;&gt;Hyperparameters&lt;/h3&gt;

&lt;p&gt;These seem like many hyperparameter to choose, but in practice there are known values for them that generally work well.
It is also not problematic if the clipping values \(\eta_{\min}\) and \(\eta_{\max}\) are respectively smaller and larger than necessary because an inconvenient step size is generally adapted quickly.&lt;/p&gt;

&lt;p&gt;Popular values for \(\alpha\) and \(\beta\) are \(1.2\) and \(0.5\).
Heuristically, it works well to increase the step size slowly, while allowing for the possibility of quickly decreasing it when jumping around an optimum.
For fine tuning the weights, it is important that \(\beta\) is not the reciprocal of \(\alpha\), to allow for many different step sizes.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;One advantage of RProp that was not discussed so far is having a different step
size for each weight.
If one weight is already very close to its optimal value while a second weight
still needs to be changed a lot, this is not a problem for RProp.
Other gradient descent variants can have much more problems with such a
situation, especially because the gradient magnitudes can be misleading here.&lt;/p&gt;

&lt;p&gt;While RProp works well in a lot of situations, it is not perfect.
For instance, RProp generally requires large batch updates.
If there’s too much randomness in SGD, then the step sizes jump around too much
and the updates work badly.&lt;/p&gt;

&lt;p&gt;Implementing RProp is quite straightforward.
To get a better understanding of RProp, reading the &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/torch/optim/rprop.py&quot;&gt;PyTorch
implementation&lt;/a&gt; can also be helpful.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] Rojas, R., 2013. Neural networks: a systematic introduction. Springer
Science &amp;amp; Business Media.&lt;/p&gt;

&lt;p&gt;[2] Riedmiller, M. and Braun, H., 1993. A direct adaptive method for faster
backpropagation learning: The RPROP algorithm. In Neural Networks, 1993., IEEE
International Conference on (pp. 586-591). IEEE.&lt;/p&gt;
</description>
        <pubDate>Sun, 08 Apr 2018 03:54:00 -0700</pubDate>
        <link>https://florian.github.io//rprop/</link>
        <guid isPermaLink="true">https://florian.github.io//rprop/</guid>
        
        
        <category>machine-learning,</category>
        
        <category>optimization</category>
        
      </item>
    
      <item>
        <title>Probabilistic Quantization</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://research.googleblog.com/2017/04/federated-learning-collaborative.html&quot;&gt;Federated Learning&lt;/a&gt;
is an exciting new subarea of machine learning where the
training process is distributed among many users [1]. It is a form of collaborative
machine learning with the constraint that the communication can be slow and
unstable.&lt;/p&gt;

&lt;p&gt;This is easily worth its &lt;a href=&quot;/federated-learning/&quot;&gt;own post&lt;/a&gt; but in a nutshell Federated
Learning works like this: A central server maintains a machine learning model.
Training data is only available locally on the users’ devices, so from time to
time they get a copy of the model and improve it using their locally available
data. The weight updates are sent back to the server where they are averaged
and the model is updated. This process is then repeated from time to time.&lt;/p&gt;

&lt;p&gt;Federated Learning is an incredibly interesting topic because it allows users to
keep their data private while a high-quality model can still be trained using
it. There are, however, some challenges for making this work. One of them is
that a naive approach leads to extremely high communication costs. Neural networks
nowadays commonly have millions of parameters and sending updates for millions
of weights from a mobile device to a server is not really desirable.&lt;/p&gt;

&lt;h3 id=&quot;probabilistic-binarization&quot;&gt;Probabilistic Binarization&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Probabilistic Binarization&lt;/em&gt;, or &lt;em&gt;Quantization&lt;/em&gt;, is one solution to this problem. I found it to be
very elegant, so I decided it would be worth writing a blog post about.
Fundamentally, it removes a lot of information from individual updates which
allows us to encode them using much fewer bits. Still, by taking into account
the aggregated weight updates from a lot of users, not much information is lost.
This concept reminds me a lot of &lt;a href=&quot;/differential-privacy/&quot;&gt;differential privacy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To understand the idea, it is important to realize that only the average is
important. If a weight update \(h\) is randomized to a compressed version \(h’\),
then \(E[h’] = h\) needs to hold. In other words, the compressed estimate needs to
be correct on average. This is called an &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias_of_an_estimator&quot;&gt;unbiased
estimator&lt;/a&gt; in statistics.&lt;/p&gt;

&lt;p&gt;Having an unbiased estimator allows us to approximate the true weight update
more closely and closely as more weight updates are sent. This is known as the &lt;em&gt;law of
large numbers&lt;/em&gt;.
A binarization scheme that implements this idea looks as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
h' = \begin{cases}
		h_{\min} &amp; \text{with probability } (h_{\max} - h) / (h_{\max} - h_{\min})  \\
		h_{\max} &amp; \text{with probability } (h - h_{\min}) / (h_{\max} - h_{\min})
	\end{cases}
    \label{eq:probailistic-binarization} %]]&gt;&lt;/script&gt;

&lt;p&gt;where \(h_{\min}\) and \(h_{\max}\) are the smallest and largest values that are
reasonable for this weight update.&lt;/p&gt;

&lt;p&gt;The denominator in the formula is a normalization factor to make sure that all
probabilities are between 0 and 1. The numerators compute the distances between
\(h\) and the two bounds. The bound that is closer to \(h\) is chosen with a
higher probability.&lt;/p&gt;

&lt;h3 id=&quot;convergence&quot;&gt;Convergence&lt;/h3&gt;

&lt;p&gt;By using this randomization technique, the estimates converge slower to the true
mean. I implemented some simulations to play with this. In the image below, 500
users sent random updates using a normal distribution centered around 0.4 with
a standard deviation of 0.3. Each simulated user sent their true update and the
randomized one. The plot shows the average after \(x\) reports arrived at the
server.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/posts/probabilistic-quantization/law-of-large-numbers.png&quot; alt=&quot;Convergence&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As shown, both mean estimates converge to 0.4. The randomized estimate has a
slower convergence but it is worth noting that 500 users are not a lot when
requiring data for machine learning. Still, it is worth noting that the formal
guarantee for convergence is a bit weaker since the training data of users is
generally differently distributed.&lt;/p&gt;

&lt;p&gt;But all in all, this is a remarkable result: Just by querying some more users,
we got the same information while each client needed to send much fewer bits.
The compressed weight update \(h’\) can be encoded using one bit (1 for \(h_{\max}\), 0 for \(h_{\min}\))
whereas the original update \(h\) was a 32- or 64-bit float. This is a
huge compression factor.&lt;/p&gt;

&lt;h3 id=&quot;probabilistic-quantization&quot;&gt;Probabilistic Quantization&lt;/h3&gt;

&lt;p&gt;The algorithm shown so far could be called &lt;em&gt;probabilistic binarization&lt;/em&gt;.
Quantization takes the idea one step further: Instead of sending one of two
possible values, \(h\) values are possible. To encode an update \(h\), the
probabilistic binarization scheme using the two closest values is applied.&lt;/p&gt;

&lt;p&gt;Of course, more bits are required to encode the possible values. The trade-off
is that convergence can be reached much quicker and that the estimates for the
largest and smallest possible values can be less accurate.&lt;/p&gt;

&lt;p&gt;Finally, it is worth noting that there are further improves to this algorithm [2].
By applying random rotations, the error when only a few users have sent their
data can be reduced. Additionally, this method can be combined with other
compression techniques for Federated Learning [2, 3].&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] McMahan, H.B., Moore, E., Ramage, D. and Hampson, S., 2016. Communication-efficient learning of deep networks from decentralized data.&lt;/p&gt;

&lt;p&gt;[2] Suresh, A.T., Yu, F.X., McMahan, H.B. and Kumar, S., 2016. Distributed mean estimation with limited communication.&lt;/p&gt;

&lt;p&gt;[3] Konečný, J., McMahan, H.B., Yu, F.X., Richtárik, P., Suresh, A.T. and Bacon, D., 2016. Federated learning: Strategies for improving communication efficiency.&lt;/p&gt;
</description>
        <pubDate>Sun, 25 Feb 2018 08:03:00 -0800</pubDate>
        <link>https://florian.github.io//probabilistic-quantization/</link>
        <guid isPermaLink="true">https://florian.github.io//probabilistic-quantization/</guid>
        
        
        <category>federated-learning</category>
        
      </item>
    
      <item>
        <title>What I read in 2017</title>
        <description>&lt;p&gt;Whenever I’m looking for a new book to read, I really enjoy looking at lists of
books other people read. Since I started reading more again this year, I thought
it’d be a good idea to write down some thoughts on the individual books.
I ended up picking up a new book pretty much every month. In the following, I
describe the more interesting ones of them.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;the-sense-of-style&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Sense-Style-Thinking-Persons-Writing/dp/0143127799/r&quot;&gt;The Sense of Style&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/sense-of-style.jpg&quot; alt=&quot;The Sense of Style cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Sense of Style is a style guide that tries to explain how to write more elegantly and
effectively. I started reading this book in the very beginning of January, when I
was in the final weeks of working on my bachelor thesis. Of course, the timing was not a
coincidence, and I do feel like the book has helped to improve my thesis a bit.&lt;/p&gt;

&lt;p&gt;To my surprise however, I also ended up finding the book itself quite enjoyable to read. Partly, this
is definitely because it is written in great style, by a highly eloquent author.
While I was reading the book, it also occured to me that I never really thought
about the fact that there are style guides for writing prose, similiarly to how
programmers have style guides for code.&lt;/p&gt;

&lt;p&gt;The book addresses not only stylistic choices but also dives into more psychological
aspects. One of these points that I really internalized is what the author
calls the &lt;em&gt;curse of knowledge&lt;/em&gt;.
By having a deep understanding of a topic, it becomes incredibly hard to explain
it in a good way to people without much prior knowledge. This is due to the fact
that we forget the difficulties we had when first learning about
the topic ourselves. Now it all seems so simple and it’s easy to fall into the
trap of thinking that certain parts are also obvious to other people.&lt;/p&gt;

&lt;h3 id=&quot;the-signal-and-the-noise&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Signal-Noise-Many-Predictions-Fail-but/dp/0143125087/&quot;&gt;The Signal and the Noise&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/signal-and-noise.jpg&quot; alt=&quot;The Signal and the Noise cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A lot of people will probably know the author, Nate Silver, for his incredibly
accurate election predictions. He is also well known for applying statistical
techniques to baseball, and for his articles at
&lt;a href=&quot;http://fivethirtyeight.com&quot;&gt;FiveThirtyEight&lt;/a&gt;, where he combines statistics with
journalism. I have to admit that this impressive biography is also what got me
interested in his book initially. While this is not the best reason to read a
book, I have to say that I really enjoyed it. Over the last year, I ended up recommending
the book to a lot of people.&lt;/p&gt;

&lt;p&gt;In each chapter, Silver explains how statistics are used to make
predictions in different fields.
The range of these applications is quite large and goes from elections over
weather reports and climate change to online pocker.
Because there is such a large variety of topics, the book never gets boring. It’s also
interesting to see how complicated things like weather predictions are, while
they are so ordinary for us that we don’t give them much thought.&lt;/p&gt;

&lt;p&gt;When I started reading the book, my expectations were a bit off, as I expected a
lot more math. Instead, the book is more concerned with explaining the
fundamental ideas on a popular scientific level. This means that the book
contains nearly no math but often gets into psychological aspects. For example,
a good part of the chapter on weather predictions is spent on explaining why some
predictions are made more inaccurate for psychological reasons. This is not
necessarily a negative criticism of the book, as I also deeply enjoyed these topics.
Lastly, I want to mention that the book also contains a really good high-level introduction to
Bayesian statistics.&lt;/p&gt;

&lt;h3 id=&quot;reinforcement-learning-an-introduction&quot;&gt;&lt;a href=&quot;http://incompleteideas.net/sutton/book/the-book.html&quot;&gt;Reinforcement Learning: An Introduction&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/rl.jpg&quot; alt=&quot;Reinforcement Learning: An Introduction cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reinforcement learning is a subarea of Machine Learning with some essential
differences to (un)supervised learning. The fundamental idea is that we want to
train an agent that learns how to perform tasks in a dynamic environment. In
contrast to supervised learning, the feedback given to the agent is delayed and
does not tell it what the best action would have been.&lt;/p&gt;

&lt;p&gt;Because reinforcement learning is a bit of a niche area in Machine Learning, I
never really got into it when I was new to the field. Still, the fundamental
idea sounded incredibly interesting to me, so in the holidays after the winter
semester I decided to work through this book. This was just in time to read the
reworked second edition.&lt;/p&gt;

&lt;p&gt;The book was written by Sutton and Barto who are renowned experts in the field
and came up with many of the most important ideas themselves. While the book
does contain a large amount of math, it’s still very accessible because
everything is explained up from the ground up.&lt;/p&gt;

&lt;p&gt;Working through the book was a lot of fun and I ended up &lt;a href=&quot;https://github.com/florian/reinforcement-learning&quot;&gt;implementing&lt;/a&gt; many algorithms from the book using Jupyter notebooks.
By now, reinforcement learning is also one of my absolute favorite areas of
machine learning, and the book definitely contributed to this. I still marvel at
the way it builds up the entire framework step by step.&lt;/p&gt;

&lt;h3 id=&quot;the-seven-habits-of-highly-effective-people&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Habits-Highly-Effective-People-Powerful/dp/1451639619/&quot;&gt;The Seven Habits of Highly Effective People&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/effective.jpg&quot; alt=&quot;The Seven Habits of Highly Effective People cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This book tries to explain what traits most successful people have in common.
The fundamental idea behind the book is that there are seven such habits that
most of these people share.
One chapter is devoted to each habit, in which it is discussed in a lot of detail.&lt;/p&gt;

&lt;p&gt;On the first few pages of the book, there is an incredible number of quotes from
well-known people that praise the book. This increased my expectations even
further, but ultimately I really did not like the book. The habits themselves all make
sense but they are discussed in a huge length, which becomes off-putting at some
point. Other advice from the book is way too over-engineered and complicated. I
feel like it would’ve made more sense to write down these ideas in a long essay
rather than 400 page book.&lt;/p&gt;

&lt;h3 id=&quot;a-clash-of-kings&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Clash-Kings-Song-Fire-Book/dp/0553579908&quot;&gt;A Clash of Kings&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/acok.jpg&quot; alt=&quot;A Clash of Kings cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A Clash of Kings&lt;/em&gt; is the second book from the &lt;em&gt;A Song of Ice and Fire&lt;/em&gt; series
that &lt;em&gt;Game of Thrones&lt;/em&gt; is based on. After I read the first book in 2016, I was
planning to read the other four books this year just so that I would be done
when the sixth book was going to come out. Unfortunately, that book got delayed further
and further and is not even out by now, so I decided to pause again after the second book.&lt;/p&gt;

&lt;p&gt;All in all, I really enjoyed the book. Knowing the important plot points from
the TV series takes some fun away, but the second book already starts to deviate
from the show, so there were still some surprises left. The writing style is
also great and I really like how each chapter is told from the point of view of
a different character.&lt;/p&gt;

&lt;h3 id=&quot;a-mathematicians-apology&quot;&gt;&lt;a href=&quot;https://www.math.ualberta.ca/mss/misc/A%20Mathematician%27s%20Apology.pdf&quot;&gt;A Mathematician’s Apology&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/apology.jpg&quot; alt=&quot;A Mathematician's Apology&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hardy was one of the most brilliant mathematicians of the 20th century. &lt;em&gt;A
Mathematician’s Apology&lt;/em&gt; is an essay from him where he tries to reason about why
it is worth spending time on mathematics. The word &lt;em&gt;apology&lt;/em&gt; refers to a
justification here.&lt;/p&gt;

&lt;p&gt;At the core, it is Hardy’s belief that the most beautiful kind of math is not
pursued for the sake of possible applications but just for the mathematics
themselves. Interestingly, he argues that number theory, his field of work, is
such an example. By now, there are of course many important applications for
number theory. Hardy compares pure mathematics to fields like poetry that are just
pursued because there is an aesthetic in them.&lt;/p&gt;

&lt;p&gt;All in all, I found the essay very interesting to read. Hearing about his point
of view made me change my perspective on certain areas of mathematics a little
bit. However, I do not agree on all his points, some of his views just seem too
excessive.&lt;/p&gt;

&lt;h3 id=&quot;how-to-win-friends-and-influence-people&quot;&gt;&lt;a href=&quot;https://www.amazon.com/How-Win-Friends-Influence-People/dp/0671027034/&quot;&gt;How To Win Friends And Influence People&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/carnegie.jpg&quot; alt=&quot;How To Win Friends And Influence People&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;How To Win Friends And Influence People&lt;/em&gt; is one of the best-selling books of
all time and can be found on many book suggestion lists. Because I heard so much
about it, I intended to read this book for quite some time. In the book,
Carnegie describes fundamental social principles.&lt;/p&gt;

&lt;p&gt;Many of these rules are fairly obvious. However, some of them are definitely
worth reading about. For example, I found the parts about criticism and how
people deal with it interesting to read about from a psychological perspective.&lt;/p&gt;

&lt;h3 id=&quot;openintro-statistics&quot;&gt;&lt;a href=&quot;https://www.openintro.org/stat/&quot;&gt;OpenIntro Statistics&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/books-2017/openintro-stats.jpg&quot; alt=&quot;OpenIntro Statistics cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After having focused my studies on Machine Learning, I felt like I learned a lot
about certain areas of statistics while not touching others at all. At some
point, I decided that I should spent a little bit of time learning the
fundamentals of statistics to be able to get a good overview of the entire
field. Especially significance tests were a part of statistics where I felt like
I really lacked knowledge.&lt;/p&gt;

&lt;p&gt;OpenIntro Statistics is a freely available textbook that seemed suitable for
this. It makes nearly no assumptions about the prior knowledge of the reader. On
the one hand this is great. You can pick up the book without revising
any other topics beforehand. But it also means that some parts of the book are
incredibly basic.&lt;/p&gt;

&lt;p&gt;This is the first book where I actively started writing
&lt;a href=&quot;https://github.com/florian/reading-notes/blob/master/1_OpenIntro-Statistics.md&quot;&gt;notes&lt;/a&gt; that
summarize the most important points and concepts. This turned out to be incredibly effective,
and I still can’t believe I never did this in an organized fashion before.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Looking back, I really like that the books cover a large number of different
genres. I also only just noticed that I only read books in English this year.
I’m pretty sure it was the same for 2016, which means I haven’t read a book in
German for at least two years.&lt;/p&gt;
</description>
        <pubDate>Fri, 30 Dec 2016 04:00:00 -0800</pubDate>
        <link>https://florian.github.io//reading-2017/</link>
        <guid isPermaLink="true">https://florian.github.io//reading-2017/</guid>
        
        
        <category>reading-notes</category>
        
      </item>
    
      <item>
        <title>Add-on recommendations for Firefox users</title>
        <description>&lt;p&gt;This is a reading suggestion for a very interesting post from the Mozilla Context Graph blog. The
blog post describes the new prototype of the Firefox add-on recommender
system: &lt;a href=&quot;https://medium.com/firefox-context-graph/add-on-recommendations-for-firefox-users-7774cc5a5117&quot;&gt;https://medium.com/firefox-context-graph/add-on-recommendations-for-firefox-users-7774cc5a5117&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It was also cross-posted to &lt;a href=&quot;https://www.a2p.it/wordpress/tech-stuff/mozilla/add-on-recommendations-for-firefox-users-a-prototype-recommender-system-leveraging-existing-data-sources/&quot;&gt;Alessio’s blog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 08 Dec 2016 15:23:10 -0800</pubDate>
        <link>https://florian.github.io//addon-recommender/</link>
        <guid isPermaLink="true">https://florian.github.io//addon-recommender/</guid>
        
        
        <category>differential-privacy</category>
        
      </item>
    
      <item>
        <title>Differential Privacy</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;span style=&quot;opacity:.5&quot;&gt;[This post was jointly written with &lt;a href=&quot;http://github.com/alexrs/&quot;&gt;Alejandro&lt;/a&gt; and also cross-posted on &lt;a href=&quot;http://alexrs.me/2017/rappor/&quot;&gt;his blog&lt;/a&gt;.]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In 2007 Netflix offered a $1 million prize for a 10% improvement in its recommendation system. They also released a training
dataset for the competing developers to train their systems. In order to protect their customer’s privacy,
&lt;a href=&quot;https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf&quot;&gt;they removed personal information and replaced IDs with random IDs&lt;/a&gt;.
But Netflix is not the only movie-rating portal out there, there are many others such as IMDb. Researchers linked the
Netflix dataset with IMDb to de-anonymize the Netflix dataset using the dates on which an user rated certain movies.
This problem isn’t new and remains an important one as today, thanks to computers, we can access larger amounts of data and process them more easily.&lt;/p&gt;

&lt;p&gt;In the mid 90s, The Massachusetts Group Insurance Commission (GIC) released anonymized data on state employees that
showed every hospital visit. The goal was to help researchers, and the state spent time removing all obvious identifiers
such as name, address and Social Security number. A graduate student started hunting for the Governor’s hospital records
in the GIC data. She knew that Governor Weld resided in Cambridge, Massachusetts, a city of 54,000 residents and seven ZIP
codes. For twenty dollars, she purchased the complete voter rolls from the city of Cambridge. This is a database
containing, among other things, the name, address, ZIP code, birth date, and sex of every voter. By combining this data
with the GIC records, she found Governor Weld with ease. Only six people in Cambridge shared his birth date, only three
of them were men, and of them, only he lived in his ZIP code.
&lt;a href=&quot;https://fpf.org/wp-content/uploads/The-Re-identification-of-Governor-Welds-Medical-Information-Daniel-Barth-Jones.pdf&quot;&gt;The Governor’s health records were de-anonymized.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So, how can we solve this problem? Personal data is already removed from the dataset, and it’s impossible to know whether
a dataset can be used to de-anonymize another one. Here is where &lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_privacy&quot;&gt;Differential Privacy&lt;/a&gt; appears.&lt;/p&gt;

&lt;p&gt;It formalizes the idea that a query should not reveal whether anyone is present in a dataset, much less what their
data are. This field was defined by &lt;a href=&quot;https://en.wikipedia.org/wiki/Cynthia_Dwork&quot;&gt;Cynthia Dwork&lt;/a&gt; In 2006, using work that
started appearing in 2003. It is based on the ideas of &lt;a href=&quot;https://en.wikipedia.org/wiki/Randomized_response&quot;&gt;randomized response&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;randomized-response&quot;&gt;Randomized response&lt;/h2&gt;
&lt;p&gt;Let’s imagine you’re asked “Do you own the attribute A?”, but you don’t want to answer directly. You can use this procedure:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Throw a coin.&lt;/li&gt;
  &lt;li&gt;If head, then answer honestly.&lt;/li&gt;
  &lt;li&gt;If tail, then throw the coin again and answer “Yes” if head, “No” if tail.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;
If the attribute \( A \) is synonymous with illegal behavior, then answering “Yes” is not incriminating.&lt;/p&gt;

&lt;p&gt;Many responses are significant. Positive responses are given to \( 1/4 \) by people who don’t have the attribute A and \( 3/4 \)
by people who possess it.&lt;/p&gt;

&lt;p&gt;Then we expect to obtain \( (1/4)(1-p) + (3/4)p = (1/4) + p/2 \) positive responses. Hence is possible to estimate p.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you’re interested in understanding more on how Differential Privacy works, &lt;a href=&quot;https://robertovitillo.com/2016/07/29/differential-privacy-for-dummies/&quot;&gt;here&lt;/a&gt; you can find more information.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now, the question is, how can we use this technique to collect more complex data?&lt;/p&gt;

&lt;h2 id=&quot;rappor&quot;&gt;RAPPOR&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42852.pdf&quot;&gt;RAPPOR&lt;/a&gt; is an algorithm developed
by Google whose main purpose is to collect data while adding random noise to guarantee Differential Privacy.&lt;/p&gt;

&lt;p&gt;Each user is assigned to one of \( m\) cohorts. The value to encode is passed through \( h\) hash functions to encode it into a Bloom filter, and noise is added with probabilities \( p, q, f \). Bloom Filters were also described in more detail on &lt;a href=&quot;/bloom-filters/&quot;&gt;this blog before&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In RAPPOR, we need to set different parameters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Size of the Bloom filter, \( k \)&lt;/strong&gt;: RAPPOR uses a &lt;a href=&quot;https://en.wikipedia.org/wiki/Bloom_filter&quot;&gt;Bloom filter&lt;/a&gt;
to report the data. When selecting the bloom filter size we should have in mind how many unique values are expected.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Number of hash functions, \( h \)&lt;/strong&gt;: Bloom filters uses hash functions to encode the values.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Number of cohorts, \( m \)&lt;/strong&gt;: To avoid collisions, RAPPOR divides the population into different cohorts.
This value must be choosen carefully. If it’s too small, collisions are still quite likely, while if it’s too large then
each individual cohort provides insufficient signal due to its small sample size.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Probabilities \( p, q, f \)&lt;/strong&gt;: Noise is added to the Bloom filter with different probabilities. This
probabilities determine the level of Differential Privacy along with the number of hash functions used.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;em&gt;Note: This is a very simplified version of RAPPOR, you shouldn’t use it in real life. For optimized implementations, &lt;a href=&quot;https://github.com/google/rappor/&quot;&gt;look at the original Google’s repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The first step is to encode the original value into the Bloom filter using \( h \) hash functions.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cohort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_hashes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bloombits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# create the bloom filter&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'0'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bloombits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# create the hash function to use&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;md5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashlib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;md5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cohort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;digest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;md5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;digest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# get the indexes for encode the original value into the  bloom filter&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;digest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bloombits&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_hashes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# set the corresponding 'bits' to 1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1'&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This Bloom filter never leaves the client. The next step is known as Permanent Randomized Response. Here the bits of the Bloom filter are set to 0 or 1 with probability \( f/2 \), or remains unchanged with probability \( 1 - f \). The resulting Bloom filter should be stored in the client and used in the future if the client needs to report the same value more than once.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_prr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SystemRandom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1'&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'0'&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The Instantaneus Randomize Response is computed using the probabilities \( p \) and \( q \). The resulting Bloom filter will have the bit in position \( i \) set to 1 with probability \( q \) if its value was 1 in the PRR, or with probability \( p \) if its value was 0. The resulting bloom filter is sent for analysis.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_irr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SystemRandom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'0'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_q&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1'&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;hashlib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SystemRandom&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# params&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_bloombits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# Number of bloom filter bits (k)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_hashes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;          &lt;span class=&quot;c&quot;&gt;# Number of bloom filter hashes (h)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_cohorts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;        &lt;span class=&quot;c&quot;&gt;# Number of cohorts (m)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prob_p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.50&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# Probability p&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prob_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# Probability q&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prob_f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.50&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# Probability f&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# original value&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;v10&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# select cohort&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SystemRandom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cohort&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_cohorts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# encode&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cohort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_hashes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bloombits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# prr&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_prr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# irr&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;irr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_irr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob_q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;irr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/posts/differential-privacy/rappor.png&quot; alt=&quot;rappor&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;rappor-analysis&quot;&gt;RAPPOR analysis&lt;/h1&gt;

&lt;p&gt;After clients have generated their randomized responses, they send them to a server.
This server has the task of aggregating the reports and figuring out which answers were actually given, and how often.
To do this, we make use of statistical techniques that are explained in the remainder of this blog post.&lt;/p&gt;

&lt;p&gt;The bit arrays are the only information we get from the clients. However, because of the Bloom filter, there are generally
infinitely many answers that lead to the same bits being set. This means that we need some set of answers that we explicitely
check for. We call this the &lt;em&gt;candidate set&lt;/em&gt;. What values are used as candidates is completely dependent on the data that we’re collecting.&lt;/p&gt;

&lt;p&gt;Of course we know what bits would be set when hashing these candidate values.
If we would also know how often each bit was truly set in the original Bloom filters, before noise was added, then we
could model this problem using an equation system. In this system, we’re looking for candidate counts so that the bits set
equal the true number of times the individual bits were set. In statistics, this corresponds to a &lt;em&gt;regression&lt;/em&gt; problem.&lt;/p&gt;

&lt;h2 id=&quot;estimating-the-counts-of-bits&quot;&gt;Estimating the counts of bits&lt;/h2&gt;

&lt;p&gt;Of course, the whole point of differential privacy is that we don’t have access to the originally set bits, so we can’t
directly solve this hypothetical equation system. But what we can do is figure out estimates for how often the bits were set.
This is possible because we can estimate how much noise was added on average. I won’t go into detail for the exact formulas,
as they help little to build intuition, but they can be found in  the original &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42852.pdf&quot;&gt;RAPPOR paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While this approach of making estimates might sound a bit messy, it actually has a fairly good theoretical backing.
By the &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_large_numbers&quot;&gt;&lt;em&gt;law of large numbers&lt;/em&gt;&lt;/a&gt;, the estimate will converge to the true counts with an increasing amount of data.
This also explains one very important constraint when using differential privacy: We need a lot of users to make sense of
the data. The estimates will be very accurate with many users. On the other hand, we can’t control for the random noise
well enough if we don’t have a good amount of data.&lt;/p&gt;

&lt;p&gt;After having estimated how often bits were changed for the randomized response, we can compute estimates for how often
the bits were set in the original Bloom filter. We’ll call these estimates our &lt;em&gt;target vector&lt;/em&gt; \( y \). Note that
this only gives us information about how often bits were set in total, across all users. We have absolutely no clue
about which users had the bits set in their original Bloom filter.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;To give a more concrete idea of where we’re going with this, we can stop for a moment and consider this simple example.
Let’s say we use a Bloom filter with three bits and two hash functions. After having received the randomized reports from
enough users, we estimate the following true bit counts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bit 1: 3000&lt;/li&gt;
  &lt;li&gt;bit 2: 4000&lt;/li&gt;
  &lt;li&gt;bit 3: 1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’re collecting data where each client can give exactly one answer out of the possible answers &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt; and &lt;em&gt;c&lt;/em&gt;.
These values correspond to our candidate set. When hashing the candidate values, the following bits would be set:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;a&lt;/em&gt;: bits 1, 2 would be set&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;b&lt;/em&gt;: bits 1, 3 would be set&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;c&lt;/em&gt;: bits 2, 3 would be set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given this information, we are looking for counts of how often the answers &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt; or &lt;em&gt;c&lt;/em&gt; were given so that we arrive at the
estimated numbers for the individual bits. The important inside here is that this is an equation system:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bit 1: count_a + count_b = 3000&lt;/li&gt;
  &lt;li&gt;bit 2: count_a + count_c = 4000&lt;/li&gt;
  &lt;li&gt;bit 3: count_b + count_c = 1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note how this is not just any kind of equation system, it’s a &lt;em&gt;linear equation system&lt;/em&gt;.
This is great as there are many well-known ways to solve linear equation systems.
The straightforward solution for this specific system is that answer &lt;em&gt;a&lt;/em&gt; was given 3000 times, &lt;em&gt;b&lt;/em&gt; was never given, while &lt;em&gt;c&lt;/em&gt;
was given 1000 times.&lt;/p&gt;

&lt;p&gt;Of course this is a very simple and artificially constructed example, it’s just meant to showcase the problem that the RAPPOR
analysis is being reduced to.&lt;/p&gt;

&lt;h2 id=&quot;creating-the-data-matrix-x&quot;&gt;Creating the data matrix X&lt;/h2&gt;

&lt;p&gt;Linear equation systems can generally be well presented using matrices and vectors. We already described out target vector
\( y \) earlier. What’s left to talk about is the data matrix \( X \). This matrix encodes what bits are set when candidate
values are hashed in different cohorts.&lt;/p&gt;

&lt;p&gt;The general idea here is that for each bit and cohort we add a row to the matrix. For each candidate value we add a column.
A cell then has value 1 if the corresponding bit would be set when hashing the corresponding candidate value in the
respective cohort. Otherwise, it has value 0.&lt;/p&gt;

&lt;p&gt;In the above simple example, where we have no cohorts, \( X \) would look like this:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
X =
  \begin{bmatrix}
    1 &amp; 1 &amp; 0 \\
    1 &amp; 0 &amp; 1 \\
    0 &amp; 1 &amp; 1
  \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now, our linear equation system can be described by \( Xb = y \) where \( b \) gives us the candidate counts that explain the set bits.&lt;/p&gt;

&lt;h2 id=&quot;linear-regression&quot;&gt;Linear regression&lt;/h2&gt;

&lt;p&gt;All of this is a little bit too simplified. Usually, we can’t directly solve this equation system.
One reason is that \( y \) only contains estimates and that our candidate set might be incomplete.
This means that the equation system might not have a perfect solution and that we’re generally only looking for an approximate one.
However, this is still a fairly standard problem in statistics and is usually
solved by fitting a linear regression model.&lt;/p&gt;

&lt;p&gt;The other problem is that our system does not entirely consist of linear equations.
It wouldn’t make sense to have negative counts.
Thus, \( b \) may only contain nonnegative values.
This makes the problem a fair bit harder to solve, but again it’s not a
completely new problem.
There are some implementations of nonnegative least squares (nnls) solvers
available that allow us to find the best approximate solution to a linear equation system with the nonnegativity constraint.&lt;/p&gt;

&lt;h2 id=&quot;significance-tests&quot;&gt;Significance tests&lt;/h2&gt;

&lt;p&gt;It’s worth keeping in mind that we’re only operating on estimates and that some hash collisions are possible. There are
many different approximations for the linear equation system and it’s not clear whether candidates with very small counts
were actually reported in the original Bloom filters.&lt;/p&gt;

&lt;p&gt;All of this screams for statistical significance tests. Computing p-values for linear regression coefficients is a standard
practice and is usually done using t-tests. In our case, we use one-sided t-tests because the nonnegativity constraint means
that extreme results are only possible in one direction.&lt;/p&gt;

&lt;p&gt;We use a significance level of 0.05 to filter out candidate values that don’t have enough evidence for their associated counts.
Because there might be a lot of candidate values, we use a &lt;a href=&quot;https://en.wikipedia.org/wiki/Bonferroni_correction&quot;&gt;Bonferroni corrected&lt;/a&gt; significance level.
Finally, only the candidate values and frequencies that we have enough confidence in are reported.&lt;/p&gt;

&lt;h2 id=&quot;evaluating-the-results&quot;&gt;Evaluating the results&lt;/h2&gt;

&lt;p&gt;To evaluate how well this works, we can perform a simple simulation. In the simulation shown here, clients report exactly one answer that’s chosen from an exponential distribution.
We can plot this distribution using a bar plot, where the index of possible answers is on the x-axis and their counts are on the y-axis.
&lt;img src=&quot;../../assets/posts/differential-privacy/original-distribution.png&quot; alt=&quot;Original distribution&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The randomization technique is then applied and the randomized reports are analysed by our algorithm. The distribution
generated by the algorithm can then be plotted on top of the previous image.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/posts/differential-privacy/reported-distribution.png&quot; alt=&quot;Reported distribution&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This simulation uses the same parameters that we plan to use in production. As one can see, it works quite well for this
original distribution. For the common candidate values, the reported counts are very close to the actual ones. However,
it’s not possible to detect candidate values that only occured very few times. There’s just not enough evidence to report
them with confidence. Of course only being able to detect common values is not necessarily a bad thing as it means more
privacy for users that gave unusual answers.&lt;/p&gt;
</description>
        <pubDate>Wed, 12 Oct 2016 06:36:20 -0700</pubDate>
        <link>https://florian.github.io//differential-privacy/</link>
        <guid isPermaLink="true">https://florian.github.io//differential-privacy/</guid>
        
        
        <category>differential-privacy</category>
        
      </item>
    
      <item>
        <title>Bloom Filters</title>
        <description>&lt;!-- http://jsbin.com/bocovofixo/edit?html,css,js,output --&gt;

&lt;p&gt;Probabilistic data structures are great. They allow us to be more efficient in
terms of time or space at the cost of only returning an approximate result.
Bloom filters are a popular such data structure. When I recently learned more
about their use cases, I found Bloom filters to be quite fascinating, so they
seem like a good topic to write a blog post about.&lt;/p&gt;

&lt;p&gt;In a nutshell, Bloom filters allow testing for set membership in a highly
efficient way. The trade-off is that they only return an approximate result.
Bloom filters either tell us that a value is definitely not in the set or that
it is &lt;em&gt;probably&lt;/em&gt; in the set.
If we consider being in the set as a positive result, this means they allow for
false positives but not for false negatives.&lt;/p&gt;

&lt;p&gt;The remainder of this blog post gives a more thorough introduction to Bloom filters and their
applications. Generally, the only prerequisites for being able to follow this
introduction are having a basic understanding of hashing and knowing what a set
is. To illustrate the ideas on a more intuitive level, I also coded up some live
demos and embedded them here.&lt;/p&gt;

&lt;h3 id=&quot;general-structure&quot;&gt;General structure&lt;/h3&gt;

&lt;p&gt;The underlying data structure for a Bloom filter is a bit array. Individual bits
in this bit array can either be set or not set. These possible states correspond
to values of 1 and 0. To efficiently change the values of bits, bitwise
operations can be used. As these are quite straight-forward, we will not go into
more detail here and just assume that we have operations for reading and writing
individual bits available.&lt;/p&gt;

&lt;p&gt;To get started with Bloom filters, let’s first consider a simple version of
them. To insert a value into the set, we use a hash function to map the value to
a valid index for the bit array. Then we change the bit corresponding to that
index to 1.&lt;/p&gt;

&lt;p&gt;To test if a value is part of our set, we hash the value and read
the corresponding bit. If it is 0, the value is definitely not in the set,
otherwise that bit would’ve been changed to 1. If the bit is 1, this
tells us that the value is &lt;em&gt;probably&lt;/em&gt; in the set. Probably, because there is a
chance that another element with the same hash value was inserted. In other
words, hash collisions are possible.&lt;/p&gt;

&lt;h3 id=&quot;evaluating-the-simple-solution&quot;&gt;Evaluating the simple solution&lt;/h3&gt;

&lt;p&gt;Below, you can find a live demo that can be used to test how well this works. As
you will notice, if the bit array is large and we insert relatively few
elements, then the probability of a hash collision is quite low. Of course, we
are assuming that the hash function is approximately uniformly distributed. As
we insert more values, hash collisions get more common and at some point we will
get too many false positives. Note that the Bloom filter below has only 32 bits
for visualization purposes.
This is an extraordinarily small Bloom filter, so we can’t add many elements
while still maintaining an acceptable false positive rate.&lt;/p&gt;

&lt;div id=&quot;bloom-simple&quot;&gt;&lt;/div&gt;

&lt;p&gt;This already highlights one important property of Bloom filters: We should have
some estimate for how many values we want to insert. This estimate should then
be used to choose an appropriate size for the bit array. By choosing a large
enough size, we can ensure that the expected number of false positives is quite
low.&lt;/p&gt;

&lt;p&gt;Let’s take a moment to reflect on this solution. Under the assumption that we
choose the array size to be large enough and that some false positives are
acceptable, we have a very fast way of testing for set membership.
Conceptionally, this solution is also pretty simple. We can think of it like a
HashSet that ignores the possibility of collisions. Because we only store a bit
array, Bloom filters are also quite space efficient, especially when compared to
methods that store the original values, like HashSets.&lt;/p&gt;

&lt;h3 id=&quot;using-multiple-hash-functions&quot;&gt;Using multiple hash functions&lt;/h3&gt;

&lt;p&gt;In terms of efficiency, the data structure given above is pretty much perfect.
The two important operations, inserting and testing membership, are both
performed in constant time. What we primarily want to improve now is the
probability of false positives.&lt;/p&gt;

&lt;p&gt;This is where Bloom filters start to get interesting. Instead of just using a
single hash function, we use &lt;em&gt;k&lt;/em&gt; hash functions. So for each value we insert, we
get &lt;em&gt;k&lt;/em&gt; indices where we set the bits to 1. For testing membership, we check
the bits corresponding to &lt;em&gt;k&lt;/em&gt; indices.&lt;/p&gt;

&lt;div id=&quot;bloom-normal&quot;&gt;&lt;/div&gt;

&lt;p&gt;This significantly decreases the chance of getting false positives. Given a
large Bloom filter without many entries, it’s unlikely to get one hash
collision. But getting &lt;em&gt;k&lt;/em&gt; collisions at the same time is even more unlikely if
most bits are not set.&lt;/p&gt;

&lt;h3 id=&quot;deciding-on-the-number-of-hash-functions&quot;&gt;Deciding on the number of hash functions&lt;/h3&gt;

&lt;p&gt;More hash functions only help until a certain point. As an extreme example,
using as many hash functions as bits would make a Bloom filter totally
useless. On a similiar note, when only having 32 bits available, using 3 hash
functions fills up the bit array too quickly, as you might have noticed in the
live demo above. In turns out that the optimal number of hash functions depends
on the bit array size and on how many elements we expect to be added.&lt;/p&gt;

&lt;p&gt;For &lt;em&gt;n&lt;/em&gt; added elements and a bit array size of &lt;em&gt;m&lt;/em&gt;, the optimal number of hash
functions &lt;em&gt;k&lt;/em&gt; is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;k = \frac{m}{n} * \ln(2)&lt;/script&gt;

&lt;p&gt;On a first look, this formula seems a bit cryptic. The logarithm is due to the
fact that we’re estimating the probability of false positives using &lt;a href=&quot;https://en.wikipedia.org/wiki/Azuma%27s_inequality&quot;&gt;Azuma’s
inequality&lt;/a&gt;, which uses the
exponential function. By transforming that inequality, we end up with the natural
logarithm. Other than that, the formula is easy to interpret. As the
bit array size increases in comparison to the expected number of added elements,
the optimal number of hash functions increases linearly.&lt;/p&gt;

&lt;p&gt;Deciding on the bit array size is also pretty straight-forward. A larger bit
array size always decreases the false positive rate. The downside is that more
space is needed. Generally, this is a trade-off where we choose the exact value
depending on the use case.&lt;/p&gt;

&lt;h3 id=&quot;applications&quot;&gt;Applications&lt;/h3&gt;

&lt;p&gt;After having only talked about the technical parts so far, let’s take a step
back and look at some applications.
Generally, Bloom filters are useful when a few false positives are acceptable to
be more space and time efficient, but false negatives are not.
In the next two subsections, we’ll go into more detail for two prime examples for Bloom filters.&lt;/p&gt;

&lt;h4 id=&quot;spelling-correction&quot;&gt;Spelling correction&lt;/h4&gt;

&lt;p&gt;To implement spelling correction, we need some way to decide whether a word is
misspelt. The Oxford English Dictionary contains more than 200,000 words.
Having all these words stored in memory all the time is a bad idea.&lt;/p&gt;

&lt;p&gt;Instead, we can insert all words from the dictionary into a Bloom filter to be
much more space efficient. The fact that false positives are possible means that
there will be a few misspelt words that will not be detected. However, no
correctly written words would be marked as incorrect. This is good because it
would only annoy users.&lt;/p&gt;

&lt;h4 id=&quot;databases&quot;&gt;Databases&lt;/h4&gt;

&lt;p&gt;Querying a database can be expensive, especially when it requires IO operations.
&lt;a href=&quot;http://cassandra.apache.org&quot;&gt;Cassandra&lt;/a&gt; uses Bloom filters to make &lt;a href=&quot;http://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlAboutReads.html&quot;&gt;reading data&lt;/a&gt;
more efficient. It’s a first filter that checks if it’s possible that a key is
contained in some table. This allows Cassandra to prevent many expensive memory
calls.&lt;/p&gt;

&lt;p&gt;A few false positives are not a problem here. They just lead to performing the
normal expensive call that would be performed anyways if the Bloom filter would
not be used at all.&lt;/p&gt;

&lt;h3 id=&quot;other-set-operations&quot;&gt;Other set operations&lt;/h3&gt;

&lt;p&gt;So far we only discussed two operations, adding elements and testing for
membership. Depending on the appliation, other operations are also interesting.
In the following, we will focus on the classical set operations, union and
intersection. Afterwards, we’ll also look at removing elements.&lt;/p&gt;

&lt;p&gt;In the next two subsections, we assume that all Bloom filters use the same hash
functions and have the same number of bits.&lt;/p&gt;

&lt;h4 id=&quot;union&quot;&gt;Union&lt;/h4&gt;

&lt;p&gt;Union is straight-forward to implement for Bloom filters. We simply
create a Bloom filter where a bit is set when it’s also set in any input Bloom
filter. This resulting Bloom filter behaves exactly as when we directly query
all original Bloom filters and only returning true if at least one individual Bloom
filters returned true.&lt;/p&gt;

&lt;h4 id=&quot;intersection&quot;&gt;Intersection&lt;/h4&gt;

&lt;p&gt;For implementing an intersection operation, we can try to follow the same idea:
Construct a Bloom filter where a bit is set when all one input Bloom filter
had the bit set. It turns out that this is not a perfect solution because it
will lead to more false positives compared to directly querying the individual
Bloom filters.&lt;/p&gt;

&lt;p&gt;To understand why, it helps to think of a Bloom filter with two hash functions.
A value is part of this Bloom filter if its respective two bits are set. In the
Bloom filter resulting from the intersection it is possible that these bits were
set because of several different values that are not in the intersection themselves.
This would not happen if we build a new Bloom filter directly from the set
intersection.&lt;/p&gt;

&lt;h3 id=&quot;removing-values&quot;&gt;Removing values&lt;/h3&gt;

&lt;p&gt;Removing values from standard Bloom filters is difficult. By just setting the
corresponding bits to 0, we could accidently introduce false negatives. This is
due to the fact that a bit maybe also needs to be set for a different added
element. We generally want to avoid false negatives with Bloom filters, so this
is not an acceptable solution.&lt;/p&gt;

&lt;p&gt;One possible solution is introducing a second Bloom filter that keeps track of
the removed values. This only works if values cannot be readded. Still, this is
not a satisfying solution since false positives in this second Bloom filter
become false negatives in the first Bloom filter.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Counting Bloom Filters&lt;/em&gt; are a more sophisticated alternative. Instead of just
using bits as boolean indicators, enough bits to keep a count at each index are
used. Then, instead of setting a bit, the count at the respective position is
increased by 1. For removing an element, the counter is decreased by 1. This
works well as long as an element is not added more than once before removing it.&lt;/p&gt;

&lt;div id=&quot;bloom-counting&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Bloom Filters are a probabilistic data structure that allow for testing set
membership in an extremely efficient way. Since they are based on bitwise operations,
they also require very little space. The trade-off is that there is a small
probability of false positives.
These false positives can be reduced by using enough bits and multiple hash functions.
There are many interesting use-cases for Bloom Filters, for example to make
caching in databases more efficient.&lt;/p&gt;

&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://fb.me/react-15.1.0.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://fb.me/react-dom-15.1.0.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/crypto-js/3.1.2/components/core-min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/crypto-js/3.1.2/rollups/hmac-md5.js&quot;&gt;&lt;/script&gt;

&lt;style&gt;
.bloom-filter {
  width: 581px;
  position: relative;
  margin-left: 30px;
  margin-bottom: 15px;
}

.bloom-filter h2 {
  font-size: 17px;
  display: inline-block;
  margin: 0;
}

.bloom-filter ul {
  list-style-type: none;
  margin: 10px auto;
  padding: 0;
}

.bloom-filter li {
  display: inline-block;
  width: 17px;
  height: 17px;
  padding: 0;
  text-indent: 0;
  border: 1px solid #565656;
  border-right: none;
  text-align: center;
  font-size: 13px;
  vertical-align:top
}

.bloom-filter li:before {
  content: '';
  padding: 0;
}


.bloom-filter ul :last-child {
  border-right: 1px solid;
}

.bloom-filter .set {
  background: grey;
  transition: background .5s ease-in;
}

.bloom-filter form {
  padding-bottom: 10px;
}

.bloom-filter input {
  display: inline-block;
  position: relative;
  vertical-align: top;
}

.bloom-filter input[type=&quot;text&quot;] {
  width: 150px;
  height: 15px;
  padding: 4px 6px;
  font-size: 14px;
  float: none;
  margin-left: 0;
  background-color: #ffffff;
  border: 1px solid #cccccc;
  outline: none;
  line-height: 20px;
  color: #555555;
  font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;
  border-radius: 4px 0 0 4px;
}

.bloom-filter input[type=&quot;submit&quot;], .bloom-filter input[type=&quot;button&quot;] {
  min-width: 100px;
  height: 25px;
  line-height: 15px;
  margin-left: -3px;
  padding: 4px 12px;
  font-size: 14px;
  color: #333333;
  text-align: center;
  text-shadow: 0 1px 1px rgba(255, 255, 255, 0.75);
  cursor: pointer;
  background-color: #e6e6e6;
  background-image: -moz-linear-gradient(top, #ffffff, #e6e6e6);
  background-image: -webkit-gradient(linear, 0 0, 0 100%, from(#ffffff), to(#e6e6e6));
  background-image: -webkit-linear-gradient(top, #ffffff, #e6e6e6);
  background-image: -o-linear-gradient(top, #ffffff, #e6e6e6);
  background-image: linear-gradient(to bottom, #ffffff, #e6e6e6);
  background-repeat: repeat-x;
  border: 1px solid #cccccc;*
  border: 0;
  border-color: #e6e6e6 #e6e6e6 #bfbfbf;
  border-color: rgba(0, 0, 0, 0.1) rgba(0, 0, 0, 0.1) rgba(0, 0, 0, 0.25);
  border-bottom-color: #b3b3b3;
  font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;
}

.bloom-filter input[type=&quot;submit&quot;]:active, .bloom-filter input[type=&quot;button&quot;]:active {
  background-color: #ffffff;
  background-image: -moz-linear-gradient(bottom, #ffffff, #e6e6e6);
  background-image: -webkit-gradient(linear, 0 0, 0 100%, from(#e6e6e6), to(#ffffff));
  background-image: -webkit-linear-gradient(bottom, #ffffff, #e6e6e6);
  background-image: -o-linear-gradient(bottom, #ffffff, #e6e6e6);
  background-image: linear-gradient(to top, #ffffff, #e6e6e6);
  background-repeat: repeat-x;
}

.bloom-filter .last-input {
  border-radius: 0 4px 4px 0;
}

.bloom-filter .elements {
  display: inline-block;
}
&lt;/style&gt;

&lt;script&gt;
&quot;use strict&quot;;

var _createClass = function () { function defineProperties(target, props) { for (var i = 0; i &lt; props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (&quot;value&quot; in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();

function _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(&quot;this hasn't been initialised - super() hasn't been called&quot;); } return call &amp;&amp; (typeof call === &quot;object&quot; || typeof call === &quot;function&quot;) ? call : self; }

function _inherits(subClass, superClass) { if (typeof superClass !== &quot;function&quot; &amp;&amp; superClass !== null) { throw new TypeError(&quot;Super expression must either be null or a function, not &quot; + typeof superClass); } subClass.prototype = Object.create(superClass &amp;&amp; superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }

function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(&quot;Cannot call a class as a function&quot;); } }

var BloomFilter = function () {
  function BloomFilter(num_bits, num_hash_functions) {
    _classCallCheck(this, BloomFilter);

    this.num_bits = num_bits;
    this.num_hash_functions = num_hash_functions;
    this._init_storage();
  }

  _createClass(BloomFilter, [{
    key: &quot;_init_storage&quot;,
    value: function _init_storage() {
      this.storage = Array(this.num_bits);
      for (var i = 0; i &lt; this.num_bits; i++) {
        this.storage[i] = false;
      }
    }
  }, {
    key: &quot;hash&quot;,
    value: function hash(value) {
      var seed = arguments.length &gt; 1 &amp;&amp; arguments[1] !== undefined ? arguments[1] : 0;

      return Math.abs(CryptoJS.MD5(value + seed).words.reduce(function (a, b) {
        return a + b;
      }), 0) % this.num_bits;
    }
  }, {
    key: &quot;add&quot;,
    value: function add(value) {
      for (var i = 0; i &lt; this.num_hash_functions; i++) {
        var hashed = this.hash(value, i);
        this.storage[hashed] = true;
      }
    }
  }, {
    key: &quot;contains&quot;,
    value: function contains(value) {
      for (var i = 0; i &lt; this.num_hash_functions; i++) {
        var hashed = this.hash(value, i);
        if (!this.storage[hashed]) return false;
      }

      return true;
    }
  }, {
    key: &quot;print&quot;,
    value: function print() {
      return this.storage.reduce(function (result, bit) {
        if (bit) {
          return result + &quot;x&quot;;
        } else {
          return result + &quot;_&quot;;
        }
      }, &quot;&quot;);
    }
  }]);

  return BloomFilter;
}();

var CountingBloomFilter = function (_BloomFilter) {
  _inherits(CountingBloomFilter, _BloomFilter);

  function CountingBloomFilter() {
    _classCallCheck(this, CountingBloomFilter);

    return _possibleConstructorReturn(this, (CountingBloomFilter.__proto__ || Object.getPrototypeOf(CountingBloomFilter)).apply(this, arguments));
  }

  _createClass(CountingBloomFilter, [{
    key: &quot;_init_storage&quot;,
    value: function _init_storage() {
      this.storage = Array(this.num_bits);
      for (var i = 0; i &lt; this.num_bits; i++) {
        this.storage[i] = 0;
      }
    }
  }, {
    key: &quot;add&quot;,
    value: function add(value) {
      for (var i = 0; i &lt; this.num_hash_functions; i++) {
        var hashed = this.hash(value, i);
        this.storage[hashed] += 1;
      }
    }
  }, {
    key: &quot;print&quot;,
    value: function print() {
      return this.storage.reduce(function (result, bit) {
        if (bit) {
          return result + String(bit);
        } else {
          return result + &quot;_&quot;;
        }
      }, &quot;&quot;);
    }
  }, {
    key: &quot;remove&quot;,
    value: function remove(value) {
      for (var i = 0; i &lt; this.num_hash_functions; i++) {
        var hashed = this.hash(value, i);
        this.storage[hashed] -= 1;
      }
    }
  }]);

  return CountingBloomFilter;
}(BloomFilter);

function plural(base, extension, n) {
  return n + &quot; &quot; + base + (n == 1 ? &quot;&quot; : extension);
}

var BloomFilterVisualization = function (_React$Component) {
  _inherits(BloomFilterVisualization, _React$Component);

  function BloomFilterVisualization(props) {
    _classCallCheck(this, BloomFilterVisualization);

    var _this2 = _possibleConstructorReturn(this, (BloomFilterVisualization.__proto__ || Object.getPrototypeOf(BloomFilterVisualization)).call(this, props));

    _this2.state = {
      bf: props.counting ? new CountingBloomFilter(props.bits, props.hash_functions) : new BloomFilter(props.bits, props.hash_functions),
      bits: props.bits,
      hash_functions: props.hash_functions,
      addedValues: [],
      simple: props.simple || false,
      lastCheck: &quot;&quot;,
      counting: props.counting || false
    };
    return _this2;
  }

  _createClass(BloomFilterVisualization, [{
    key: &quot;render&quot;,
    value: function render() {
      var data_structure = &quot;Bloom Filter&quot;;
      if (this.state.counting) {
        data_structure = &quot;Counting &quot; + data_structure;
      }

      return React.createElement(
        &quot;div&quot;,
        { className: &quot;bloom-filter&quot; },
        React.createElement(
          &quot;h2&quot;,
          null,
          &quot;Live Demo: &quot;,
          data_structure,
          &quot; with &quot;,
          this.state.bits,
          &quot; bits and &quot;,
          plural(&quot;hash function&quot;, &quot;s&quot;, this.state.hash_functions),
          &quot; &quot;
        ),
        React.createElement(
          &quot;ul&quot;,
          null,
          this.state.bf.storage.map(this.renderBit.bind(this))
        ),
        this.renderForm(),
        React.createElement(
          &quot;div&quot;,
          { className: &quot;elements&quot; },
          &quot;Added so far: &quot;,
          &quot;{&quot;,
          &quot; &quot;,
          this.state.addedValues.join(&quot;, &quot;),
          &quot; &quot;,
          &quot;}&quot;
        ),
        this.state.lastCheck != &quot;&quot; ? React.createElement(
          &quot;div&quot;,
          null,
          this.state.lastCheck
        ) : &quot;&quot;
      );
    }
  }, {
    key: &quot;renderBit&quot;,
    value: function renderBit(bit, i) {
      var className = &quot;&quot;,
          content = &quot;&quot;;

      if (this.state.counting) {
        content = bit == 0 ? &quot;&quot; : String(bit);
      } else {
        className = bit ? &quot;set&quot; : &quot;not-set&quot;;
      }

      return React.createElement(
        &quot;li&quot;,
        { className: className, key: i },
        content
      );
    }
  }, {
    key: &quot;renderForm&quot;,
    value: function renderForm() {
      return React.createElement(
        &quot;form&quot;,
        { onSubmit: this.add.bind(this) },
        React.createElement(&quot;input&quot;, { type: &quot;text&quot;, ref: &quot;value&quot; }),
        this.state.simple ? React.createElement(&quot;input&quot;, { type: &quot;submit&quot;, value: &quot;Add&quot;, className: &quot;last-input&quot; }) : &quot;&quot;,
        !this.state.simple ? React.createElement(&quot;input&quot;, { type: &quot;submit&quot;, value: &quot;Add&quot; }) : &quot;&quot;,
        this.state.counting ? React.createElement(&quot;input&quot;, { type: &quot;button&quot;, value: &quot;Remove&quot;, onClick: this.remove.bind(this) }) : &quot;&quot;,
        !this.state.simple ? React.createElement(&quot;input&quot;, { type: &quot;button&quot;, value: &quot;Check for membership&quot;, className: &quot;last-input&quot;, onClick: this.check.bind(this) }) : &quot;&quot;
      );
    }
  }, {
    key: &quot;add&quot;,
    value: function add(e) {
      e.preventDefault();

      var input = this.refs.value;
      var value = input.value;
      input.select();

      if (value.trim() == &quot;&quot;) return false;

      var addedValues = this.state.addedValues;
      var inSet = addedValues.indexOf(value) != -1;

      if (this.state.counting &amp;&amp; inSet) {
        var confirmed = confirm(&quot;Adding an already added value will partly break the Counting Bloom filter. Do you still want to continue?&quot;);
        if (!confirmed) {
          return false;
        }
      }

      var bf = this.state.bf;
      bf.add(value);

      if (!inSet) addedValues.push(value);

      this.setState({
        bf: bf,
        addedValues: addedValues
      });
    }
  }, {
    key: &quot;check&quot;,
    value: function check(e) {
      e.preventDefault();

      var input = this.refs.value;
      var value = input.value;
      input.select();

      if (value.trim() == &quot;&quot;) return false;

      var bf = this.state.bf;
      var isContained = bf.contains(value);

      this.setState({
        lastCheck: value + &quot; was &quot; + (isContained ? &quot;&quot; : &quot;not &quot;) + &quot;found&quot;
      });
    }
  }, {
    key: &quot;remove&quot;,
    value: function remove(e) {
      e.preventDefault();

      var input = this.refs.value;
      var value = input.value;
      input.select();

      if (value.trim() == &quot;&quot;) return false;

      var addedValues = this.state.addedValues;
      var inSet = addedValues.indexOf(value) != -1;

      if (!inSet) {
        var confirmed = confirm(&quot;Removing a value that's not in the set will partly break the Counting Bloom filter. Do you still want to continue?&quot;);
        if (!confirmed) {
          return false;
        }
      }

      this.state.bf.remove(value);
      addedValues.splice(addedValues.indexOf(value), 1);

      this.setState({
        addedValues: addedValues
      });
    }
  }]);

  return BloomFilterVisualization;
}(React.Component);

ReactDOM.render(React.createElement(BloomFilterVisualization, { bits: 32, hash_functions: 1 }), document.getElementById(&quot;bloom-simple&quot;));
ReactDOM.render(React.createElement(BloomFilterVisualization, { bits: 32, hash_functions: 3 }), document.getElementById(&quot;bloom-normal&quot;));
ReactDOM.render(React.createElement(BloomFilterVisualization, { bits: 32, hash_functions: 3, counting: true }), document.getElementById(&quot;bloom-counting&quot;));
&lt;/script&gt;

</description>
        <pubDate>Sat, 03 Sep 2016 12:36:20 -0700</pubDate>
        <link>https://florian.github.io//bloom-filters/</link>
        <guid isPermaLink="true">https://florian.github.io//bloom-filters/</guid>
        
        
        <category>probabilistic-data-structures</category>
        
      </item>
    
  </channel>
</rss>
